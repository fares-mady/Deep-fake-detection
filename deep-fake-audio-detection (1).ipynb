{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8130934,"sourceType":"datasetVersion","datasetId":4555568}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### üì¶ Install Required Python Packages\n\nThis cell installs the necessary Python libraries for audio processing, machine learning, and data balancing:\n\n- `librosa`: A powerful library for audio and music analysis, useful for feature extraction from sound files.\n- `pip --upgrade`: Ensures that `pip`, Python's package installer, is up to date to avoid installation issues.\n- `xgboost`: A high-performance gradient boosting library used for classification and regression tasks.\n- `imblearn`: Contains tools for handling imbalanced datasets, such as SMOTE for oversampling.\n- `pydub`: A library for audio manipulation, including reading, converting, and slicing audio files.\n\n```python\n!pip install librosa\n!pip install --upgrade pip\n!pip install xgboost\n!pip install imblearn\n!pip install pydub\n","metadata":{}},{"cell_type":"markdown","source":"### üìö Importing Required Libraries\n\nThis cell prepares the environment by importing libraries essential for:\n\n- **Operating System Interaction**:\n  - `os`: Allows file and directory manipulation, such as reading file names or navigating folders.\n\n- **Numerical Computation**:\n  - `numpy`: Provides support for efficient array operations and numerical calculations.\n\n- **Audio Processing & Visualization**:\n  - `librosa`: A specialized library for loading audio files and extracting audio features (like MFCCs).\n  - `librosa.display`: Contains functions to visualize audio data, such as waveforms and spectrograms.\n\n- **Machine Learning with Scikit-learn**:\n  - `train_test_split`: Splits the dataset into training and testing sets.\n  - `GridSearchCV`: Automates hyperparameter tuning using cross-validation.\n  - `StratifiedKFold`: Ensures balanced class distribution in cross-validation folds.\n  - `cross_validate`: Performs evaluation using multiple metrics and splits.\n  - `StandardScaler`: Normalizes data by removing the mean and scaling to unit variance.\n  - `classification_report`, `confusion_matrix`, `accuracy_score`: Provide metrics for evaluating model performance.\n\n- **Model Training**:\n  - `XGBClassifier`: The XGBoost classifier, known for its speed and accuracy in classification tasks.\n\n- **Handling Imbalanced Data**:\n  - `SMOTE` (Synthetic Minority Over-sampling Technique): Generates synthetic samples to balance class distributions in the training data.\n\n- **Audio File Manipulation**:\n  - `AudioSegment` (from `pydub`): Facilitates audio file conversion and editing (e.g., from MP3 to WAV).\n\n> These imports set the foundation for building a machine learning pipeline focused on audio classification tasks.\n","metadata":{}},{"cell_type":"code","source":"!pip install librosa\n!pip install --upgrade pip\n!pip install xgboost\n!pip install imblearn\n!pip install pydub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T14:35:00.850228Z","iopub.execute_input":"2025-05-10T14:35:00.850430Z","iopub.status.idle":"2025-05-10T14:35:37.545882Z","shell.execute_reply.started":"2025-05-10T14:35:00.850408Z","shell.execute_reply":"2025-05-10T14:35:37.541407Z"}},"outputs":[{"name":"stdout","text":"Collecting librosa\n  Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m260.7/260.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pooch>=1.1\n  Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting audioread>=2.1.9\n  Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\nRequirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.10/site-packages (from librosa) (2.0.2)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/site-packages (from librosa) (1.1.0)\nRequirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.10/site-packages (from librosa) (4.13.1)\nCollecting soxr>=0.3.2\n  Downloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting numba>=0.51.0\n  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/site-packages (from librosa) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/site-packages (from librosa) (5.2.1)\nRequirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.10/site-packages (from librosa) (1.6.1)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/site-packages (from librosa) (1.15.2)\nCollecting soundfile>=0.12.1\n  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting lazy_loader>=0.1\n  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from lazy_loader>=0.1->librosa) (24.2)\nCollecting llvmlite<0.45,>=0.44.0dev0\n  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.3)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.3.7)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\nInstalling collected packages: soxr, llvmlite, lazy_loader, audioread, soundfile, pooch, numba, librosa\nSuccessfully installed audioread-3.0.1 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.44.0 numba-0.61.2 pooch-1.8.2 soundfile-0.13.1 soxr-0.5.0.post1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: pip in /usr/local/lib/python3.10/site-packages (23.0.1)\nCollecting pip\n  Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.0.1\n    Uninstalling pip-23.0.1:\n      Successfully uninstalled pip-23.0.1\nSuccessfully installed pip-25.1.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting xgboost\n  Downloading xgboost-3.0.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from xgboost) (2.0.2)\nRequirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/site-packages (from xgboost) (2.21.5)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from xgboost) (1.15.2)\nDownloading xgboost-3.0.0-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: xgboost\nSuccessfully installed xgboost-3.0.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0mCollecting imblearn\n  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\nCollecting imbalanced-learn (from imblearn)\n  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\nRequirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (2.0.2)\nRequirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.15.2)\nRequirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.6.1)\nCollecting sklearn-compat<1,>=0.1 (from imbalanced-learn->imblearn)\n  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (1.4.2)\nRequirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from imbalanced-learn->imblearn) (3.6.0)\nDownloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\nDownloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\nDownloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\nInstalling collected packages: sklearn-compat, imbalanced-learn, imblearn\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3/3\u001b[0m [imblearn]2/3\u001b[0m [imblearn]d-learn]\n\u001b[1A\u001b[2KSuccessfully installed imbalanced-learn-0.13.0 imblearn-0.0 sklearn-compat-0.1.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0mCollecting pydub\n  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\nDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\nInstalling collected packages: pydub\nSuccessfully installed pydub-0.25.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install --upgrade scikit-learn imbalanced-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T14:35:37.548158Z","iopub.execute_input":"2025-05-10T14:35:37.548420Z","iopub.status.idle":"2025-05-10T14:35:39.509256Z","shell.execute_reply.started":"2025-05-10T14:35:37.548392Z","shell.execute_reply":"2025-05-10T14:35:39.504466Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/site-packages (1.6.1)\nRequirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/site-packages (0.13.0)\nRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (2.0.2)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.10/site-packages (from imbalanced-learn) (0.1.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install --upgrade scikit-learn imbalanced-learn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T14:35:39.511459Z","iopub.execute_input":"2025-05-10T14:35:39.511700Z","iopub.status.idle":"2025-05-10T14:35:41.446109Z","shell.execute_reply.started":"2025-05-10T14:35:39.511677Z","shell.execute_reply":"2025-05-10T14:35:41.441772Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/site-packages (1.6.1)\nRequirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/site-packages (0.13.0)\nRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (2.0.2)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.10/site-packages (from imbalanced-learn) (0.1.3)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport numpy as np\nimport librosa\nimport librosa.display\nimport sklearn\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_validate\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom xgboost import XGBClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom pydub import AudioSegment","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-10T14:35:41.448335Z","iopub.execute_input":"2025-05-10T14:35:41.448601Z","iopub.status.idle":"2025-05-10T14:35:47.058856Z","shell.execute_reply.started":"2025-05-10T14:35:41.448575Z","shell.execute_reply":"2025-05-10T14:35:47.054490Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### üéôÔ∏è `extract_features` Function Explanation\n\nThis function is designed to extract audio features from a given file for use in machine learning models, particularly for tasks like audio classification. Here's what each part does:\n\n---\n\n#### üîß Parameters:\n- `file_path (str)`: Path to the audio file (.mp3 or .wav).\n- `sample_rate (int, optional)`: Target sample rate for loading audio. If `None`, uses the default.\n- `augment (bool)`: Whether to apply audio data augmentation.\n- `is_real (bool)`: Whether to apply more aggressive augmentation (e.g., time stretching) for real recordings.\n\n---\n\n#### ü™Ñ Main Steps:\n\n1. **Convert MP3 to WAV** (if needed):\n   - If the input is an `.mp3` file, it is converted to a temporary `.wav` file using `pydub`.\n   - This avoids decoding issues and allows `librosa` to process it.\n\n2. **Load the Audio File**:\n   - Uses `librosa.load()` to read the audio data and its sample rate.\n\n3. **Clean Up**:\n   - Deletes the temporary `.wav` file created during MP3 conversion.\n\n4. **Data Augmentation (Optional)**:\n   - Adds Gaussian noise.\n   - Randomly shifts the pitch.\n   - If `is_real` is `True`, also applies time stretching to simulate real-world variation.\n\n5. **Feature Extraction**:\n   - **MFCC (Mel-frequency cepstral coefficients)**: Captures timbral features of the sound.\n   - **Spectral Contrast**: Measures the difference between peaks and valleys in the spectrum.\n   - **ZCR (Zero Crossing Rate)**: Indicates signal noisiness or texture.\n\n6. **Feature Aggregation**:\n   - For each feature, both the **mean** and **standard deviation** are computed across time frames.\n   - All these statistics are concatenated into a single feature vector (`np.ndarray`).\n\n7. **Return**:\n   - Returns the final 1D feature vector.\n   - If any error occurs (e.g., decoding failure), the function prints an error and returns `None`.\n\n---\n\n> üîÅ This function enables consistent preprocessing and feature extraction from various audio file types, making it highly suitable for training and evaluating machine learning models.\n","metadata":{}},{"cell_type":"code","source":"def extract_features(file_path: str, sample_rate: int = None, augment: bool = False, is_real: bool = False) -> np.ndarray:\n    try:\n        # Handle .mp3 files by converting to .wav in a writable directory\n        if file_path.endswith('.mp3'):\n            try:\n                audio = AudioSegment.from_mp3(file_path)\n                temp_wav_path = os.path.join('/kaggle/working/', os.path.basename(file_path).replace('.mp3', '_temp.wav'))\n                audio.export(temp_wav_path, format='wav')\n                file_path = temp_wav_path\n            except Exception as mp3_error:\n                print(f\"Skipping {file_path}: Failed to decode .mp3 file - {str(mp3_error)}\")\n                return None\n        \n        # Load audio file\n        audio, sr = librosa.load(file_path, sr=sample_rate)\n        \n        # Clean up temporary file if created\n        if file_path.endswith('_temp.wav'):\n            os.remove(file_path)\n        \n        # Apply augmentation if enabled\n        if augment:\n            noise = np.random.normal(0, 0.015, audio.shape)\n            audio = audio + noise\n            audio = librosa.effects.pitch_shift(audio, sr=sr, n_steps=np.random.uniform(-4, 4))\n            if is_real:\n                audio = librosa.effects.time_stretch(audio, rate=np.random.uniform(0.6, 1.4))\n        \n        # Extract features (MFCC, spectral contrast, ZCR)\n        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n        spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)\n        zcr = librosa.feature.zero_crossing_rate(audio)\n        \n        # Compute statistics (mean and std) for each feature\n        mfcc_mean = np.mean(mfcc, axis=1)\n        mfcc_std = np.std(mfcc, axis=1)\n        spectral_contrast_mean = np.mean(spectral_contrast, axis=1)\n        spectral_contrast_std = np.std(spectral_contrast, axis=1)\n        zcr_mean = np.mean(zcr)\n        zcr_std = np.std(zcr)\n        \n        # Concatenate all features into a single vector\n        features = np.concatenate([\n            mfcc_mean, mfcc_std,\n            spectral_contrast_mean, spectral_contrast_std,\n            [zcr_mean, zcr_std]\n        ])\n        \n        return features\n    \n    except Exception as e:\n        print(f\"Error extracting features from {file_path}: {str(e)}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T14:35:47.061099Z","iopub.execute_input":"2025-05-10T14:35:47.061450Z","iopub.status.idle":"2025-05-10T14:35:47.074939Z","shell.execute_reply.started":"2025-05-10T14:35:47.061426Z","shell.execute_reply":"2025-05-10T14:35:47.070961Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### üìÇ `load_dataset` Function Explanation\n\nThis function loads and processes audio data from a structured directory of real and fake audio samples, returning feature arrays and their corresponding labels for machine learning tasks.\n\n---\n\n#### üîß Parameters:\n- `for_base_path (str)`: Root path where the audio folders (`for-2sec`, `for-norm`, etc.) are located.\n- `augment (bool, default=True)`: Whether to apply data augmentation (noise, pitch shift, time stretch).\n- `max_files_per_split (int, optional)`: If set, limits the number of audio files processed per data split (training/testing/validation).\n\n---\n\n#### ü™Ñ Workflow Overview:\n\n1. **Helper Function ‚Äì `get_audio_files(directory)`**:\n   - Gathers all `.wav` and `.mp3` files from a given directory.\n   - Respects the `max_files_per_split` limit if specified.\n\n2. **Dataset Initialization**:\n   - Initializes empty lists `X` (features) and `y` (labels).\n   - Tracks the number of skipped files due to errors.\n\n3. **Iterate Through Audio Folders**:\n   - Loops through the subfolders: `for-2sec`, `for-norm`, `for-original`, `for-rerec`.\n   - Each subfolder contains `training`, `testing`, and `validation` folders.\n\n4. **Process Real and Fake Audio Files**:\n   - For each split:\n     - **Real audio files** are labeled with `0`.\n     - **Fake audio files** are labeled with `1`.\n     - For each file:\n       - Features are extracted using `extract_features()`.\n       - If `augment` is `True`, the augmented version is also added.\n\n5. **Error Handling**:\n   - Files that fail during processing are counted and reported.\n\n6. **Return**:\n   - Returns:\n     - `X`: NumPy array of extracted feature vectors.\n     - `y`: NumPy array of labels (0 for real, 1 for fake).\n   - Prints the count of loaded samples and skipped files.\n\n---\n\n> üìå **Directory Assumptions**:\n> The function expects a directory structure like:\n> ```\n> for_base_path/\n> ‚îî‚îÄ‚îÄ for-original/\n>     ‚îî‚îÄ‚îÄ for-original/\n>         ‚îú‚îÄ‚îÄ training/\n>         ‚îÇ   ‚îú‚îÄ‚îÄ real/\n>         ‚îÇ   ‚îî‚îÄ‚îÄ fake/\n>         ‚îî‚îÄ‚îÄ testing/\n>             ‚îú‚îÄ‚îÄ real/\n>             ‚îî‚îÄ‚îÄ fake/\n> ```\n\n> ‚úÖ This function prepares labeled data for training or evaluating a binary classifier that distinguishes real from fake audio.\n","metadata":{}},{"cell_type":"code","source":"def load_dataset(for_base_path: str, augment: bool = True, max_files_per_split: int = None) -> tuple[np.ndarray, np.ndarray]:\n    def get_audio_files(directory: str) -> list[str]:\n        \"\"\"Get list of .wav and .mp3 files in a directory.\"\"\"\n        try:\n            files = [\n                os.path.join(directory, f) for f in os.listdir(directory)\n                if (f.endswith('.wav') or f.endswith('.mp3')) and os.path.isfile(os.path.join(directory, f))\n            ]\n            if max_files_per_split is not None:\n                files = files[:max_files_per_split]\n            return files\n        except Exception as e:\n            print(f\"Error reading directory {directory}: {str(e)}\")\n            return []\n\n    X, y = [], []\n    skipped_files = 0\n    \n    for folder in ['for-2sec', 'for-norm', 'for-original', 'for-rerec']:\n        subfolder_path = os.path.join(for_base_path, folder, folder)\n        for split in ['training', 'testing', 'validation']:\n            split_path = os.path.join(subfolder_path, split)\n            if os.path.exists(split_path):\n                real_path = os.path.join(split_path, 'real')\n                if os.path.exists(real_path):\n                    for file in get_audio_files(real_path):\n                        features = extract_features(file, augment=augment, is_real=True)\n                        if features is not None:\n                            X.append(features)\n                            y.append(0)\n                            if augment:\n                                aug_features = extract_features(file, augment=True, is_real=True)\n                                if aug_features is not None:\n                                    X.append(aug_features)\n                                    y.append(0)\n                                else:\n                                    skipped_files += 1\n                        else:\n                            skipped_files += 1\n                \n                fake_path = os.path.join(split_path, 'fake')\n                if os.path.exists(fake_path):\n                    for file in get_audio_files(fake_path):\n                        features = extract_features(file, augment=augment, is_real=False)\n                        if features is not None:\n                            X.append(features)\n                            y.append(1)\n                            if augment:\n                                aug_features = extract_features(file, augment=True, is_real=False)\n                                if aug_features is not None:\n                                    X.append(aug_features)\n                                    y.append(1)\n                                else:\n                                    skipped_files += 1\n                        else:\n                            skipped_files += 1\n    \n    if not X:\n        raise ValueError(\"No valid audio files processed.\")\n    \n    y = np.array(y)\n    print(f\"Loaded {len(X)} samples (real: {np.sum(y == 0)}, fake: {np.sum(y == 1)})\")\n    print(f\"Skipped {skipped_files} files due to errors.\")\n    \n    return np.array(X), y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T14:35:47.077207Z","iopub.execute_input":"2025-05-10T14:35:47.077426Z","iopub.status.idle":"2025-05-10T14:35:47.102286Z","shell.execute_reply.started":"2025-05-10T14:35:47.077405Z","shell.execute_reply":"2025-05-10T14:35:47.095620Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### ü§ñ `train_model` Function Explanation\n\nThis function trains an XGBoost classification model on the provided feature matrix `X` and label vector `y`, with optional hyperparameter tuning and class balancing strategies to improve performance on imbalanced datasets.\n\n---\n\n#### üîß Parameters:\n- `X (np.ndarray)`: Feature matrix containing preprocessed audio features.\n- `y (np.ndarray)`: Labels corresponding to the features (0 = real, 1 = fake).\n- `tune_hyperparameters (bool, default=False)`: Whether to perform hyperparameter optimization using grid search.\n\n---\n\n### üß† Training Workflow:\n\n#### 1. **Compute Class Weights**\n- Determines the imbalance between real and fake classes.\n- Adjusts `scale_pos_weight` for XGBoost accordingly, helping the model focus on the minority class.\n\n#### 2. **Initialize the XGBoost Model**\n- Uses predefined parameters (like `max_depth`, `learning_rate`, regularization, etc.).\n- Integrates class weighting via `scale_pos_weight`.\n\n#### 3. **Feature Scaling**\n- Applies `StandardScaler` to normalize the feature values ‚Äî an essential step before training many ML models.\n\n#### 4. **Apply SMOTE (Synthetic Minority Oversampling Technique)**\n- Balances the dataset by synthetically generating new samples of the minority class.\n- Helps improve model generalization and reduce bias.\n\n#### 5. **(Optional) Hyperparameter Tuning**\n- If `tune_hyperparameters=True`, performs grid search using `GridSearchCV`:\n  - Explores combinations of parameters (e.g., `n_estimators`, `max_depth`, `learning_rate`, etc.).\n  - Evaluates using 5-fold cross-validation with the `f1_macro` score.\n\n#### 6. **Model Training**\n- If hyperparameter tuning is **not** enabled:\n  - Splits data into training and validation sets.\n  - Trains the model with early stopping on the validation set to prevent overfitting.\n\n#### 7. **Cross-Validation Evaluation**\n- Uses `StratifiedKFold` to maintain label distribution across folds.\n- Reports metrics:\n  - Accuracy\n  - Precision (macro)\n  - Recall (macro)\n  - F1-score (macro)\n  - ROC AUC\n- Displays mean and standard deviation for each metric across folds.\n\n#### 8. **Return Values**\n- Returns:\n  - The trained `XGBClassifier` model.\n  - The `StandardScaler` used for preprocessing (important for transforming future input data).\n\n---\n\n> ‚úÖ This function builds a robust classifier for detecting fake audio, handling class imbalance, applying best practices in preprocessing, and optionally tuning the model for optimal performance.\n","metadata":{}},{"cell_type":"code","source":"def train_model(X: np.ndarray, y: np.ndarray, tune_hyperparameters: bool = False) -> tuple[XGBClassifier, StandardScaler]:\n    try:\n        # Compute class weights for imbalanced dataset\n        n_real = sum(y == 0)\n        n_fake = sum(y == 1)\n        class_weight_ratio = n_fake / n_real\n        class_weights = {0: class_weight_ratio, 1: 1.0}\n        \n        # Initialize model\n        model = XGBClassifier(\n            n_estimators=80,\n            max_depth=3,\n            learning_rate=0.05,\n            reg_alpha=0.5,\n            reg_lambda=2.0,\n            subsample=0.7,\n            colsample_bytree=0.7,\n            random_state=42,\n            scale_pos_weight=class_weights[0]\n        )\n        scaler = StandardScaler()\n        \n        # Normalize features\n        X_scaled = scaler.fit_transform(X)\n        \n        # Apply SMOTE to balance classes\n        smote = SMOTE(random_state=42)\n        X_scaled, y = smote.fit_resample(X_scaled, y)\n        \n        if tune_hyperparameters:\n            param_grid = {\n                'n_estimators': [60, 80, 100],\n                'max_depth': [2, 3, 4],\n                'learning_rate': [0.01, 0.05],\n                'reg_alpha': [0.1, 0.5, 1.0],\n                'reg_lambda': [1.0, 2.0, 3.0],\n                'subsample': [0.6, 0.7],\n                'colsample_bytree': [0.6, 0.7]\n            }\n            grid_search = GridSearchCV(\n                model, param_grid, cv=5, scoring='f1_macro', n_jobs=-1\n            )\n            grid_search.fit(X_scaled, y)\n            model = grid_search.best_estimator_\n            print(f\"Best parameters: {grid_search.best_params_}\")\n        else:\n            X_train, X_val, y_train, y_val = train_test_split(\n                X_scaled, y, test_size=0.1, random_state=42, stratify=y\n            )\n            model.fit(\n                X_train, y_train,\n                eval_set=[(X_val, y_val)],\n                eval_metric='logloss',\n                early_stopping_rounds=15,\n                verbose=True\n            )\n        \n        # Perform cross-validation with stratified k-fold\n        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n        cv_scores = cross_validate(model, X_scaled, y, cv=cv, scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc'], return_train_score=False)\n        print(\"Cross-validation results:\")\n        for metric in ['test_accuracy', 'test_precision_macro', 'test_recall_macro', 'test_f1_macro', 'test_roc_auc']:\n            scores = cv_scores[metric]\n            print(f\"{metric}: {np.mean(scores):.4f} (+/- {np.std(scores):.4f})\")\n        return model, scaler\n    \n    except Exception as e:\n        print(f\"Error during training: {str(e)}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T14:35:47.103893Z","iopub.execute_input":"2025-05-10T14:35:47.104114Z","iopub.status.idle":"2025-05-10T14:35:47.120938Z","shell.execute_reply.started":"2025-05-10T14:35:47.104094Z","shell.execute_reply":"2025-05-10T14:35:47.114484Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### üìä `evaluate_model` Function Explanation\n\nThis function evaluates a trained XGBoost model on a test dataset, printing out key performance metrics.\n\n---\n\n#### üîß Parameters:\n- `model (XGBClassifier)`: The trained classifier.\n- `scaler (StandardScaler)`: The scaler used during training (to ensure consistent feature scaling).\n- `X_test (np.ndarray)`: Feature matrix for the test set.\n- `y_test (np.ndarray)`: True labels for the test set.\n\n---\n\n### üß™ Evaluation Steps:\n\n#### 1. **Feature Scaling**\n- Transforms `X_test` using the same `StandardScaler` that was fitted on the training data.\n\n#### 2. **Prediction**\n- Computes class probabilities with `model.predict_proba()`.\n- Converts probabilities to binary predictions using a threshold of `0.5`:\n  - If probability ‚â• 0.5 ‚Üí class `1` (Fake).\n  - Otherwise ‚Üí class `0` (Real).\n\n#### 3. **Metric Calculation**\n- **Accuracy**: Overall correctness of predictions.\n- **Classification Report**:\n  - Precision, recall, and F1-score for each class (`Real`, `Fake`).\n- **Confusion Matrix**:\n  - Shows the number of true positives, false positives, true negatives, and false negatives.\n\n#### 4. **Display Results**\n- Prints all computed metrics clearly to summarize how well the model performs on unseen data.\n\n---\n\n> üìå Use this function to validate the model‚Äôs effectiveness and identify any performance issues such as class imbalance or poor generalization.\n","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model: XGBClassifier, scaler: StandardScaler, X_test: np.ndarray, y_test: np.ndarray) -> None:\n    try:\n        X_test_scaled = scaler.transform(X_test)\n        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n        y_pred = (y_pred_proba >= 0.5).astype(int)\n        \n        accuracy = accuracy_score(y_test, y_pred)\n        report = classification_report(y_test, y_pred, target_names=['Real', 'Fake'])\n        conf_matrix = confusion_matrix(y_test, y_pred)\n        \n        print(f\"Test Accuracy: {accuracy:.4f}\")\n        print(\"Classification Report:\\n\", report)\n        print(\"Confusion Matrix:\\n\", conf_matrix)\n    \n    except Exception as e:\n        print(f\"Error during evaluation: {str(e)}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T14:35:47.122439Z","iopub.execute_input":"2025-05-10T14:35:47.122655Z","iopub.status.idle":"2025-05-10T14:35:47.133640Z","shell.execute_reply.started":"2025-05-10T14:35:47.122636Z","shell.execute_reply":"2025-05-10T14:35:47.128238Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### üîç `predict_fake_audio` Function Explanation\n\nThis function takes a trained model and a new audio file, and predicts whether the audio is real or fake.\n\n---\n\n#### üîß Parameters:\n- `model (XGBClassifier)`: The pre-trained classifier.\n- `scaler (StandardScaler)`: The scaler fitted on training data, used to normalize new input features.\n- `file_path (str)`: Path to the audio file (.wav or .mp3) to be predicted.\n\n---\n\n### üß† Prediction Workflow:\n\n#### 1. **File Validation**\n- Checks if the file exists at the specified path.\n- If not found, raises a `FileNotFoundError`.\n\n#### 2. **Feature Extraction**\n- Calls `extract_features()` with:\n  - `augment=False`: No data augmentation.\n  - `is_real=False`: Treated as a test-time prediction (not training).\n- If extraction fails, raises a `ValueError`.\n\n#### 3. **Feature Scaling**\n- Applies the same `StandardScaler` used during training to normalize the extracted features.\n\n#### 4. **Model Prediction**\n- Uses `model.predict_proba()` to get the probability of the audio being fake.\n- Applies a threshold of `0.5`:\n  - `proba ‚â• 0.5` ‚Üí Predicts **Fake audio**\n  - `proba < 0.5` ‚Üí Predicts **Real audio**\n\n#### 5. **Returns**\n- A human-readable prediction: either `\"Real audio\"` or `\"Fake audio\"`.\n\n---\n\n> üéØ This function allows for real-time or batch inference on unseen audio data using a trained anti-spoofing model.\n","metadata":{}},{"cell_type":"code","source":"def predict_fake_audio(model: XGBClassifier, scaler: StandardScaler, file_path: str) -> str:\n    if not os.path.exists(file_path):\n        print(f\"File not found: {file_path}\")\n        raise FileNotFoundError(f\"File not found: {file_path}\")\n    \n    features = extract_features(file_path, augment=False, is_real=False)\n    if features is None:\n        raise ValueError(f\"Could not extract features from {file_path}\")\n    \n    features_scaled = scaler.transform([features])\n    proba = model.predict_proba(features_scaled)[0, 1]\n    prediction = 1 if proba >= 0.5 else 0\n    \n    return \"Real audio\" if prediction == 0 else \"Fake audio\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T14:35:47.134991Z","iopub.execute_input":"2025-05-10T14:35:47.135207Z","iopub.status.idle":"2025-05-10T14:35:47.147468Z","shell.execute_reply.started":"2025-05-10T14:35:47.135188Z","shell.execute_reply":"2025-05-10T14:35:47.142194Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### üìÅ Dataset Loading and Initialization\n\nThis code initializes the path to the dataset and loads a manageable subset of the data for testing.\n\n---\n\n#### üìå Code Breakdown:\n\n```python\n# Define dataset path\nfor_base_path = '/kaggle/input/the-fake-or-real-dataset/'\n","metadata":{}},{"cell_type":"code","source":"# Define dataset path\nfor_base_path = '/kaggle/input/the-fake-or-real-dataset/'\n\n# Load dataset with a limit for initial testing\nprint(\"Loading dataset...\")\nX, y = load_dataset(for_base_path, augment=True, max_files_per_split=1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T14:35:47.148097Z","iopub.execute_input":"2025-05-10T14:35:47.148314Z","iopub.status.idle":"2025-05-10T15:18:13.317423Z","shell.execute_reply.started":"2025-05-10T14:35:47.148292Z","shell.execute_reply":"2025-05-10T15:18:13.312633Z"}},"outputs":[{"name":"stdout","text":"Loading dataset...\nSkipping /kaggle/input/the-fake-or-real-dataset/for-original/for-original/training/fake/file17407.mp3: Failed to decode .mp3 file - Decoding failed. ffmpeg returned error code: 1\n\nOutput from ffmpeg/avlib:\n\nffmpeg version 5.1.6-0+deb12u1 Copyright (c) 2000-2024 the FFmpeg developers\n  built with gcc 12 (Debian 12.2.0-14)\n  configuration: --prefix=/usr --extra-version=0+deb12u1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librist --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --disable-sndio --enable-libjxl --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-libplacebo --enable-librav1e --enable-shared\n  libavutil      57. 28.100 / 57. 28.100\n  libavcodec     59. 37.100 / 59. 37.100\n  libavformat    59. 27.100 / 59. 27.100\n  libavdevice    59.  7.100 / 59.  7.100\n  libavfilter     8. 44.100 /  8. 44.100\n  libswscale      6.  7.100 /  6.  7.100\n  libswresample   4.  7.100 /  4.  7.100\n  libpostproc    56.  6.100 / 56.  6.100\n[mp3 @ 0x58e77f7fc440] Failed to read frame size: Could not seek to 1026.\n/kaggle/input/the-fake-or-real-dataset/for-original/for-original/training/fake/file17407.mp3: Invalid argument\n\nSkipping /kaggle/input/the-fake-or-real-dataset/for-original/for-original/training/fake/file19851.mp3: Failed to decode .mp3 file - Decoding failed. ffmpeg returned error code: 1\n\nOutput from ffmpeg/avlib:\n\nffmpeg version 5.1.6-0+deb12u1 Copyright (c) 2000-2024 the FFmpeg developers\n  built with gcc 12 (Debian 12.2.0-14)\n  configuration: --prefix=/usr --extra-version=0+deb12u1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librist --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --disable-sndio --enable-libjxl --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-libplacebo --enable-librav1e --enable-shared\n  libavutil      57. 28.100 / 57. 28.100\n  libavcodec     59. 37.100 / 59. 37.100\n  libavformat    59. 27.100 / 59. 27.100\n  libavdevice    59.  7.100 / 59.  7.100\n  libavfilter     8. 44.100 /  8. 44.100\n  libswscale      6.  7.100 /  6.  7.100\n  libswresample   4.  7.100 /  4.  7.100\n  libpostproc    56.  6.100 / 56.  6.100\n[mp3 @ 0x5b91a1238440] Failed to read frame size: Could not seek to 1077.\n/kaggle/input/the-fake-or-real-dataset/for-original/for-original/training/fake/file19851.mp3: Invalid argument\n\nSkipping /kaggle/input/the-fake-or-real-dataset/for-original/for-original/validation/fake/file31606.mp3: Failed to decode .mp3 file - Decoding failed. ffmpeg returned error code: 1\n\nOutput from ffmpeg/avlib:\n\nffmpeg version 5.1.6-0+deb12u1 Copyright (c) 2000-2024 the FFmpeg developers\n  built with gcc 12 (Debian 12.2.0-14)\n  configuration: --prefix=/usr --extra-version=0+deb12u1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librist --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --disable-sndio --enable-libjxl --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-libplacebo --enable-librav1e --enable-shared\n  libavutil      57. 28.100 / 57. 28.100\n  libavcodec     59. 37.100 / 59. 37.100\n  libavformat    59. 27.100 / 59. 27.100\n  libavdevice    59.  7.100 / 59.  7.100\n  libavfilter     8. 44.100 /  8. 44.100\n  libswscale      6.  7.100 /  6.  7.100\n  libswresample   4.  7.100 /  4.  7.100\n  libpostproc    56.  6.100 / 56.  6.100\n[mp3 @ 0x58601a31a440] Failed to read frame size: Could not seek to 1026.\n/kaggle/input/the-fake-or-real-dataset/for-original/for-original/validation/fake/file31606.mp3: Invalid argument\n\nLoaded 23994 samples (real: 12000, fake: 11994)\nSkipped 3 files due to errors.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Split data with stratification\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:18:13.319743Z","iopub.execute_input":"2025-05-10T15:18:13.320230Z","iopub.status.idle":"2025-05-10T15:18:13.341600Z","shell.execute_reply.started":"2025-05-10T15:18:13.320203Z","shell.execute_reply":"2025-05-10T15:18:13.337515Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Train model with hyperparameter tuning\nprint(\"Training model...\")\nmodel, scaler = train_model(X_train, y_train, tune_hyperparameters=True)\n        \n# Evaluate model\nprint(\"Evaluating model...\")\nevaluate_model(model, scaler, X_test, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:18:13.344242Z","iopub.execute_input":"2025-05-10T15:18:13.344479Z","iopub.status.idle":"2025-05-10T15:18:49.565480Z","shell.execute_reply.started":"2025-05-10T15:18:13.344455Z","shell.execute_reply":"2025-05-10T15:18:49.559320Z"}},"outputs":[{"name":"stdout","text":"Training model...\nBest parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.6}\nCross-validation results:\ntest_accuracy: 0.9558 (+/- 0.0052)\ntest_precision_macro: 0.9560 (+/- 0.0052)\ntest_recall_macro: 0.9558 (+/- 0.0052)\ntest_f1_macro: 0.9558 (+/- 0.0052)\ntest_roc_auc: 0.9906 (+/- 0.0012)\nEvaluating model...\nTest Accuracy: 0.9580\nClassification Report:\n               precision    recall  f1-score   support\n\n        Real       0.97      0.95      0.96      3600\n        Fake       0.95      0.97      0.96      3599\n\n    accuracy                           0.96      7199\n   macro avg       0.96      0.96      0.96      7199\nweighted avg       0.96      0.96      0.96      7199\n\nConfusion Matrix:\n [[3413  187]\n [ 115 3484]]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### üß™ Example Prediction\n\nThis code snippet demonstrates how to use the trained model to make a prediction on a new audio file.\n\n---\n\n#### üìå Code Breakdown:\n\n```python\n# Example prediction\nnew_audio_file = input(\"Enter the path to the audio file to check: \")\n","metadata":{}},{"cell_type":"code","source":"# Example prediction\nnew_audio_file = input(\"Enter the path to the audio file to check: \")\nresult = predict_fake_audio(model, scaler, new_audio_file)\nprint(f\"Prediction for {new_audio_file}: {result}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T15:18:49.568343Z","iopub.execute_input":"2025-05-10T15:18:49.568602Z","iopub.status.idle":"2025-05-10T15:54:19.342138Z","shell.execute_reply.started":"2025-05-10T15:18:49.568576Z","shell.execute_reply":"2025-05-10T15:54:19.337006Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter the path to the audio file to check:  /kaggle/input/the-fake-or-real-dataset/for-norm/for-norm/testing/fake/file1003.wav_16k.wav_norm.wav_mono.wav_silence.wav\n"},{"name":"stdout","text":"Prediction for /kaggle/input/the-fake-or-real-dataset/for-norm/for-norm/testing/fake/file1003.wav_16k.wav_norm.wav_mono.wav_silence.wav: Fake audio\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}